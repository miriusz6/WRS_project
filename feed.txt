Things to improve:

1. State the dataset name. DONE
2. Avoid using implementation specific details about the code (e.g. lines 25-26), rather explain what you did. DONE
3. State which duplicates you removed, e.g. the most or least recent?  DONE
4. Table 1: Clarify whether this is the training or test set. DONE
5. You should report how many users/items/interactions are in the cleaned sets in a table. DONE
6. Put the stats stated at the start of section 1.0.2 in a table. DONE
7. Present the optimal models as well as the RMSE (missing) of the gridsearch, ideally in a table.
8. Avoid stating that you fit the models to the training data. We "train/tune" models to data. DONE
9. The report is missing a table with the optimal hyperparameter values after the 5-fold training, and the best RMSE scores averaged over the 5 folds. DONE
10. In section 2.2.1, put the scores at the beginning of the first paragraph in a table. 
11. Coverage is missing from the top 10 recommendations evaluation.  DONE
12. Missing: discussion of model performance with respect to the rank-based evaluation measures.